{
  "version": "1.0",
  "truncation": null,
  "padding": null,
  "added_tokens": [],
  "normalizer": null,
  "pre_tokenizer": {
    "type": "WhitespaceSplit"
  },
  "post_processor": null,
  "decoder": null,
  "model": {
    "type": "WordLevel",
    "vocab": {
      "1": 0,
      "2": 1,
      "3": 2,
      "[UNK]": 3,
      "114514": 9,
      "<|begin_of_text|>": 10,
      "<|end_of_text|>": 11
    },
    "unk_token": "[UNK]"
  }
}