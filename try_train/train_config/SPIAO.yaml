# config.yaml
# 用于配置 LlamaRec 训练脚本的参数文件

# --- 1. 路径配置 ---
paths:
  dataset_path: "/zhdd/home/kfwang/20250613Rec-Factory/data/amazon_SPIAO_from_qspan/llama_pt_format.json"
  output_dir: "/zhdd/home/kfwang/20250613Rec-Factory/try_train/llama-rec_SPIAO-checkpoints"
  tokenizer_dir: "/zhdd/home/kfwang/20250613Rec-Factory/try_train/hybrid_item_tokenizer_SPIAO"

# --- 2. 数据和模型架构配置 ---
model_params:
  # 数据预处理相关
  max_seq_length: 128
  
  # LlamaRecConfig 模型架构相关
  hidden_size: 256
  intermediate_size: 512
  num_hidden_layers: 4
  num_attention_heads: 4
  rms_norm_eps: 1.0e-6

# --- 3. 训练过程配置 ---
# 这些参数将直接传递给 transformers.TrainingArguments
training_args:
  per_device_train_batch_size: 128
  per_device_eval_batch_size: 128
  gradient_accumulation_steps: 1
  learning_rate: 5.0e-4
  num_train_epochs: 20
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.0
  logging_steps: 100
  save_strategy: "epoch"
  eval_strategy: "epoch" 
  save_total_limit: 20
  fp16: true
  report_to: "tensorboard"
  remove_unused_columns: false
  batch_eval_metrics: true

# --- 4. 数据集划分配置 ---
dataset_split:
  test_size: 0.1
  seed: 42